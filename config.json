{
  "model": {
    "vocab_size": 10000,
    "d_model": 512,
    "n_heads": 8,
    "n_layers": 6,
    "d_ff": 2048,
    "max_seq_len": 512,
    "dropout": 0.1
  },
  "training": {
    "batch_size": 32,
    "learning_rate": 1e-4,
    "num_epochs": 10,
    "max_length": 512
  },
  "inference": {
    "max_length": 100,
    "temperature": 1.0,
    "top_k": 50,
    "top_p": 0.9
  }
}


